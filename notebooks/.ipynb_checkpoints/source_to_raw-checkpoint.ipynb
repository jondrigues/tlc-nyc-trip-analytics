{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503fff14-58aa-4c4c-b1ad-8019216161ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import concurrent.futures\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    LongType,\n",
    "    TimestampType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    TimestampNTZType\n",
    ")\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark import SparkConf\n",
    "from py4j.java_gateway import Py4JJavaError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215d7af0-88ce-48a5-af9d-5e976af959cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /opt/conda/lib/python3.11/site-packages (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "spark_conf = SparkConf()\n",
    "spark_conf.set(\"spark.executor.memory\", \"4g\")\n",
    "spark_conf.set(\"spark.driver.memory\", \"2g\")\n",
    "spark_conf.set(\"spark.network.timeout\", \"600s\")\n",
    "spark_conf.set(\"spark.executor.instances\", \"4\")\n",
    "spark_conf.set(\"spark.executor.cores\", \"4\")\n",
    "spark_conf.set(\"spark.default.parallelism\", \"8\")\n",
    "spark_conf.set(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "spark_conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f447f134-c66d-4055-843e-8628d7a87c83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: green-2018-01\n",
      "Executing: green-2018-02\n",
      "Executing: green-2018-03\n",
      "Executing: green-2018-04\n",
      "Executing: green-2018-05\n",
      "Executing: green-2018-06\n",
      "Executing: green-2018-07\n",
      "Executing: green-2018-08\n",
      "Executing: green-2018-09\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "File already downloaded. Skipping download execution\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2018-10\n",
      "Executing: green-2018-11\n",
      "Executing: green-2018-12\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2019-01\n",
      "Executing: green-2019-02\n",
      "Executing: green-2019-03\n",
      "Executing: green-2019-04\n",
      "Executing: green-2019-05\n",
      "Executing: green-2019-06\n",
      "Executing: green-2019-07\n",
      "Executing: green-2019-08\n",
      "Executing: green-2019-09\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2019-10\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2019-11\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2019-12\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2020-01Executing: green-2020-02\n",
      "\n",
      "Executing: green-2020-03\n",
      "Executing: green-2020-04\n",
      "Executing: green-2020-05\n",
      "Executing: green-2020-06\n",
      "Executing: green-2020-07\n",
      "Executing: green-2020-08\n",
      "Executing: green-2020-09\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2020-10\n",
      "Executing: green-2020-11\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2020-12\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2021-01Executing: green-2021-02\n",
      "\n",
      "Executing: green-2021-03\n",
      "Executing: green-2021-04\n",
      "Executing: green-2021-05\n",
      "Executing: green-2021-06\n",
      "Executing: green-2021-07\n",
      "Executing: green-2021-08\n",
      "Executing: green-2021-09\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2021-10\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2021-11\n",
      "Executing: green-2021-12\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2022-01\n",
      "Executing: green-2022-02\n",
      "Executing: green-2022-03\n",
      "Executing: green-2022-04\n",
      "Executing: green-2022-05\n",
      "Executing: green-2022-06\n",
      "Executing: green-2022-07\n",
      "Executing: green-2022-08\n",
      "Executing: green-2022-09\n",
      "File already downloaded. Skipping download execution\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2022-10\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2022-11\n",
      "Falling back to inferring schema.\n",
      "Executing: green-2022-12\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n",
      "Falling back to inferring schema.\n"
     ]
    }
   ],
   "source": [
    "with SparkSession.builder.config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\").config(conf=spark_conf).getOrCreate() as spark:\n",
    "\n",
    "    def delete_file(file_path):\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"File {file_path} deleted successfuly.\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error deleting file {file_path}: {e}\")\n",
    "    \n",
    "    def create_dir(dir):\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "\n",
    "    def copy_file(source_path, destination_path):\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "\n",
    "    def file_exists(file_path):\n",
    "        return os.path.exists(file_path)\n",
    "\n",
    "    def is_directory_empty(directory_path):\n",
    "        return len(os.listdir(directory_path)) == 0\n",
    "    \n",
    "    def download_tripdata(table_name, year, month):\n",
    "        time.sleep(random.randint(0, 15))\n",
    "        url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{table_name}_tripdata_{year}-{month}.parquet\"\n",
    "        create_dir(f\"data/landing/{table_name}/{year}/{month}\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                if file_exists(f'data/landing/{table_name}/{year}/{month}/{table_name}_{year}-{month}.parquet'):\n",
    "                    print(\"File already downloaded. Skipping download execution\")\n",
    "                    break\n",
    "                with requests.get(url, stream=True) as r:\n",
    "                    r.raise_for_status()\n",
    "                    with open(f'data/landing/{table_name}/{year}/{month}/{table_name}_{year}-{month}.parquet', 'wb') as out_file:\n",
    "                        shutil.copyfileobj(r.raw, out_file)\n",
    "                break\n",
    "            except (Exception, requests.exceptions.RequestException) as e:\n",
    "                print(f\"Request failed with: {e}. Retrying...\")\n",
    "                time.sleep(90)\n",
    "\n",
    "\n",
    "    def download_and_normalize_data(table_name, year, month):\n",
    "        \n",
    "        print(f\"Executing: {table_name}-{year}-{month}\")\n",
    "        download_tripdata(table_name, year, month)\n",
    "        parquet_source_location = f\"data/landing/{table_name}/{year}/{month}\"\n",
    "        parquet_load_location = f\"data/raw/{table_name}/{year}/{month}\"\n",
    "        create_dir(parquet_load_location)\n",
    "\n",
    "        try:\n",
    "            df = spark.read.parquet(parquet_source_location)\n",
    "            schema_correct = all([field.name in df.columns and field.dataType == df.schema[field.name].dataType for field in get_schema(table_name).fields])\n",
    "            if not schema_correct:\n",
    "                print(\"Falling back to inferring schema.\")\n",
    "                \n",
    "                schema = get_schema(table_name)\n",
    "                for field in schema.fields:\n",
    "                    column_name = field.name\n",
    "                    data_type = field.dataType\n",
    "                    df = df.withColumn(column_name, col(column_name).cast(data_type))\n",
    "    \n",
    "                df.write.mode('overwrite').parquet(parquet_load_location)\n",
    "            else:\n",
    "                file = f\"{table_name}_{year}-{month}.parquet\"\n",
    "                if is_directory_empty(parquet_load_location):\n",
    "                    copy_file(parquet_source_location+f\"/{file}\", parquet_load_location+f\"/{file}\")\n",
    "                else:\n",
    "                    print(f\"Files already loaded for {file}\")\n",
    "        except Py4JJavaError as e:\n",
    "            file = f\"{table_name}_{year}-{month}.parquet\"\n",
    "            delete_file(parquet_source_location+f\"/{file}\")\n",
    "            download_and_normalize_data(table_name, year, month)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file: {parquet_source_location} with {e}\")\n",
    "\n",
    "\n",
    "    def get_schema(table_name):\n",
    "        if table_name == \"yellow\":\n",
    "            return StructType([\n",
    "                StructField(\"VendorID\", LongType(), True),\n",
    "                StructField(\"tpep_pickup_datetime\", TimestampNTZType(), True),\n",
    "                StructField(\"tpep_dropoff_datetime\", TimestampNTZType(), True),\n",
    "                StructField(\"passenger_count\", LongType(), True),\n",
    "                StructField(\"trip_distance\", DoubleType(), True),\n",
    "                StructField(\"RatecodeID\", LongType(), True),\n",
    "                StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "                StructField(\"PULocationID\", LongType(), True),\n",
    "                StructField(\"DOLocationID\", LongType(), True),\n",
    "                StructField(\"payment_type\", LongType(), True),\n",
    "                StructField(\"fare_amount\", DoubleType(), True),\n",
    "                StructField(\"extra\", DoubleType(), True),\n",
    "                StructField(\"mta_tax\", DoubleType(), True),\n",
    "                StructField(\"tip_amount\", DoubleType(), True),\n",
    "                StructField(\"tolls_amount\", DoubleType(), True),\n",
    "                StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "                StructField(\"total_amount\", DoubleType(), True),\n",
    "                StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "                StructField(\"airport_fee\", DoubleType(), True),\n",
    "            ])\n",
    "        elif table_name == \"green\":\n",
    "            return StructType([\n",
    "                StructField(\"VendorID\", LongType(), True),\n",
    "                StructField(\"lpep_pickup_datetime\", TimestampNTZType(), True),\n",
    "                StructField(\"lpep_dropoff_datetime\", TimestampNTZType(), True),\n",
    "                StructField(\"passenger_count\", LongType(), True),\n",
    "                StructField(\"trip_distance\", DoubleType(), True),\n",
    "                StructField(\"RatecodeID\", LongType(), True),\n",
    "                StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "                StructField(\"PULocationID\", LongType(), True),\n",
    "                StructField(\"DOLocationID\", LongType(), True),\n",
    "                StructField(\"payment_type\", LongType(), True),\n",
    "                StructField(\"fare_amount\", DoubleType(), True),\n",
    "                StructField(\"extra\", DoubleType(), True),\n",
    "                StructField(\"mta_tax\", DoubleType(), True),\n",
    "                StructField(\"tip_amount\", DoubleType(), True),\n",
    "                StructField(\"tolls_amount\", DoubleType(), True),\n",
    "                StructField(\"ehail_fee\", IntegerType(), True),\n",
    "                StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "                StructField(\"total_amount\", DoubleType(), True),\n",
    "                StructField(\"trip_type\", DoubleType(), True),\n",
    "                StructField(\"congestion_surcharge\", DoubleType(), True)\n",
    "            ])\n",
    "        else:\n",
    "            raise ValueError(f\"Table name '{table_name}' is not supported.\")\n",
    "\n",
    "    demo_download_list = [\n",
    "        [\"yellow\", \"2018\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"yellow\", \"2019\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"yellow\", \"2020\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"yellow\", \"2021\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"yellow\", \"2022\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"green\", \"2018\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"green\", \"2019\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"green\", \"2020\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"green\", \"2021\", [str(x).zfill(2) for x in range(1, 13)]],\n",
    "        [\"green\", \"2022\", [str(x).zfill(2) for x in range(1, 13)]]\n",
    "    ]\n",
    "\n",
    "    def parallel_download_and_normalize_data(demo_download):\n",
    "        table_name, year, months = demo_download\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            futures = []\n",
    "            for month in months:\n",
    "                future = executor.submit(download_and_normalize_data, table_name, year, month)\n",
    "                futures.append(future)\n",
    "            concurrent.futures.wait(futures)\n",
    "\n",
    "    for demo_download in demo_download_list:\n",
    "        parallel_download_and_normalize_data(demo_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93e2df7-e740-45d3-b20e-4f8be0a08edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: integer (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: double (nullable = true)\n",
      " |-- trip_type: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n",
      "Executing: green-2022-01\n",
      "File already downloaded. Skipping download execution\n",
      "data/landing/green/2022/01\n",
      "False\n",
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: double (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- passenger_count: double (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: integer (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: double (nullable = true)\n",
      " |-- trip_type: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import os\n",
    "import findspark\n",
    "import time\n",
    "import random\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    LongType,\n",
    "    TimestampType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    TimestampNTZType\n",
    ")\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark import SparkConf\n",
    "from py4j.java_gateway import Py4JJavaError\n",
    "\n",
    "spark = SparkSession.builder.config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"true\")\n",
    "df = spark.read.parquet(\"data/landing/green/2022/01\")\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "def delete_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "        print(f\"File {file_path} deleted successfuly.\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error deleting file {file_path}: {e}\")\n",
    "\n",
    "def create_dir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "def copy_file(source_path, destination_path):\n",
    "    shutil.copy2(source_path, destination_path)\n",
    "\n",
    "def file_exists(file_path):\n",
    "    return os.path.exists(file_path)\n",
    "\n",
    "\n",
    "def download_tripdata(table_name, year, month):\n",
    "    time.sleep(random.randint(0, 15))\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{table_name}_tripdata_{year}-{month}.parquet\"\n",
    "    create_dir(f\"data/landing/{table_name}/{year}/{month}\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            if file_exists(f'data/landing/{table_name}/{year}/{month}/{table_name}_{year}-{month}.parquet'):\n",
    "                print(\"File already downloaded. Skipping download execution\")\n",
    "                break\n",
    "            with requests.get(url, stream=True) as r:\n",
    "                r.raise_for_status()\n",
    "                with open(f'data/landing/{table_name}/{year}/{month}/{table_name}_{year}-{month}.parquet', 'wb') as out_file:\n",
    "                    shutil.copyfileobj(r.raw, out_file)\n",
    "            break\n",
    "        except (Exception, requests.exceptions.RequestException) as e:\n",
    "            print(f\"Request failed with: {e}. Retrying...\")\n",
    "            time.sleep(90)\n",
    "\n",
    "def get_schema(table_name):\n",
    "    if table_name == \"yellow\":\n",
    "        return StructType([\n",
    "            StructField(\"VendorID\", LongType(), True),\n",
    "            StructField(\"tpep_pickup_datetime\", TimestampNTZType(), True),\n",
    "            StructField(\"tpep_dropoff_datetime\", TimestampNTZType(), True),\n",
    "            StructField(\"passenger_count\", LongType(), True),\n",
    "            StructField(\"trip_distance\", DoubleType(), True),\n",
    "            StructField(\"RatecodeID\", LongType(), True),\n",
    "            StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "            StructField(\"PULocationID\", LongType(), True),\n",
    "            StructField(\"DOLocationID\", LongType(), True),\n",
    "            StructField(\"payment_type\", LongType(), True),\n",
    "            StructField(\"fare_amount\", DoubleType(), True),\n",
    "            StructField(\"extra\", DoubleType(), True),\n",
    "            StructField(\"mta_tax\", DoubleType(), True),\n",
    "            StructField(\"tip_amount\", DoubleType(), True),\n",
    "            StructField(\"tolls_amount\", DoubleType(), True),\n",
    "            StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "            StructField(\"total_amount\", DoubleType(), True),\n",
    "            StructField(\"congestion_surcharge\", DoubleType(), True),\n",
    "            StructField(\"airport_fee\", DoubleType(), True),\n",
    "        ])\n",
    "    elif table_name == \"green\":\n",
    "        return StructType([\n",
    "            StructField(\"VendorID\", LongType(), True),\n",
    "            StructField(\"tpep_pickup_datetime\", TimestampNTZType(), True),\n",
    "            StructField(\"tpep_dropoff_datetime\", TimestampNTZType(), True),\n",
    "            StructField(\"passenger_count\", LongType(), True),\n",
    "            StructField(\"trip_distance\", DoubleType(), True),\n",
    "            StructField(\"RatecodeID\", LongType(), True),\n",
    "            StructField(\"store_and_fwd_flag\", StringType(), True),\n",
    "            StructField(\"PULocationID\", LongType(), True),\n",
    "            StructField(\"DOLocationID\", LongType(), True),\n",
    "            StructField(\"payment_type\", LongType(), True),\n",
    "            StructField(\"fare_amount\", DoubleType(), True),\n",
    "            StructField(\"extra\", DoubleType(), True),\n",
    "            StructField(\"mta_tax\", DoubleType(), True),\n",
    "            StructField(\"tip_amount\", DoubleType(), True),\n",
    "            StructField(\"tolls_amount\", DoubleType(), True),\n",
    "            StructField(\"ehail_fee\", IntegerType(), True),\n",
    "            StructField(\"improvement_surcharge\", DoubleType(), True),\n",
    "            StructField(\"total_amount\", DoubleType(), True),\n",
    "            StructField(\"trip_type\", DoubleType(), True),\n",
    "            StructField(\"congestion_surcharge\", DoubleType(), True)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(f\"Table name '{table_name}' is not supported.\")\n",
    "\n",
    "def download_and_normalize_data(table_name, year, month):\n",
    "    \n",
    "    print(f\"Executing: {table_name}-{year}-{month}\")\n",
    "    download_tripdata(table_name, year, month)\n",
    "    parquet_source_location = f\"data/landing/{table_name}/{year}/{month}\"\n",
    "    print(parquet_source_location)\n",
    "    parquet_load_location = f\"data/raw/{table_name}/{year}/{month}\"\n",
    "    create_dir(parquet_load_location)\n",
    "\n",
    "    try:\n",
    "        df = spark.read.parquet(parquet_source_location)\n",
    "        schema_correct = all([field.name in df.columns and field.dataType == df.schema[field.name].dataType for field in get_schema(table_name).fields])\n",
    "        print(schema_correct)\n",
    "        df.printSchema()\n",
    "        return\n",
    "        if not schema_correct:\n",
    "            print(\"Falling back to inferring schema.\")\n",
    "            \n",
    "            schema = get_schema(table_name)\n",
    "            for field in schema.fields:\n",
    "                column_name = field.name\n",
    "                data_type = field.dataType\n",
    "                df = df.withColumn(column_name, col(column_name).cast(data_type))\n",
    "\n",
    "            df.write.mode('overwrite').parquet(parquet_load_location)\n",
    "        else:\n",
    "            file = f\"{table_name}_{year}-{month}.parquet\"\n",
    "            copy_file(parquet_source_location+f\"/{file}\", parquet_load_location+f\"/{file}\")\n",
    "    except Py4JJavaError as e:\n",
    "        print(e)\n",
    "        file = f\"{table_name}_{year}-{month}.parquet\"\n",
    "        delete_file(parquet_source_location+f\"/{file}\")\n",
    "        download_and_normalize_data(table_name, year, month)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {parquet_source_location} with {e}\")\n",
    "\n",
    "\n",
    "download_and_normalize_data(\"green\", \"2022\", \"01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
