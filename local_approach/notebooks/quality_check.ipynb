{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf52fba9-6d84-4ad4-8589-ad3ebe695fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soda-core-spark-df\n",
      "  Using cached soda_core_spark_df-3.0.39-py3-none-any.whl (3.1 kB)\n",
      "Collecting soda-core-spark==3.0.39 (from soda-core-spark-df)\n",
      "  Using cached soda_core_spark-3.0.39-py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: pyspark in /usr/local/spark/python (from soda-core-spark-df) (3.4.0)\n",
      "Collecting soda-core==3.0.39 (from soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached soda_core-3.0.39-py3-none-any.whl (177 kB)\n",
      "Collecting markupsafe<=2.1.1,>=2.0.1 (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached MarkupSafe-2.1.1-cp311-cp311-linux_x86_64.whl\n",
      "Requirement already satisfied: Jinja2<4.0,>=2.11 in /opt/conda/lib/python3.11/site-packages (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (3.1.2)\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.11/site-packages (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (8.1.3)\n",
      "Requirement already satisfied: ruamel.yaml<0.18.0,>=0.17.0 in /opt/conda/lib/python3.11/site-packages (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (0.17.31)\n",
      "Requirement already satisfied: requests~=2.27 in /opt/conda/lib/python3.11/site-packages (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (2.31.0)\n",
      "Collecting antlr4-python3-runtime~=4.11.1 (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached antlr4_python3_runtime-4.11.1-py3-none-any.whl (144 kB)\n",
      "Collecting opentelemetry-api~=1.16.0 (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached opentelemetry_api-1.16.0-py3-none-any.whl (57 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http~=1.16.0 (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.16.0-py3-none-any.whl (21 kB)\n",
      "Collecting sqlparse~=0.4 (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Collecting inflect~=6.0 (from soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached inflect-6.0.4-py3-none-any.whl (34 kB)\n",
      "Collecting py4j==0.10.9.7 (from pyspark->soda-core-spark-df)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Collecting pydantic>=1.9.1 (from inflect~=6.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached pydantic-1.10.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-api~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (67.7.2)\n",
      "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
      "Collecting opentelemetry-proto==1.16.0 (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached opentelemetry_proto-1.16.0-py3-none-any.whl (52 kB)\n",
      "Collecting opentelemetry-sdk~=1.16.0 (from opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached opentelemetry_sdk-1.16.0-py3-none-any.whl (94 kB)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.19 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-proto==1.16.0->opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (4.21.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests~=2.27->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests~=2.27->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests~=2.27->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests~=2.27->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (2023.5.7)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /opt/conda/lib/python3.11/site-packages (from ruamel.yaml<0.18.0,>=0.17.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (0.2.7)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached wrapt-1.15.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.37b0 (from opentelemetry-sdk~=1.16.0->opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df)\n",
      "  Using cached opentelemetry_semantic_conventions-0.37b0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.11/site-packages (from opentelemetry-sdk~=1.16.0->opentelemetry-exporter-otlp-proto-http~=1.16.0->soda-core==3.0.39->soda-core-spark==3.0.39->soda-core-spark-df) (4.6.3)\n",
      "Installing collected packages: py4j, antlr4-python3-runtime, wrapt, sqlparse, pydantic, opentelemetry-semantic-conventions, opentelemetry-proto, markupsafe, googleapis-common-protos, backoff, inflect, deprecated, opentelemetry-api, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, soda-core, soda-core-spark, soda-core-spark-df\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 2.1.3\n",
      "    Uninstalling MarkupSafe-2.1.3:\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\n",
      "Successfully installed antlr4-python3-runtime-4.11.1 backoff-2.2.1 deprecated-1.2.14 googleapis-common-protos-1.59.0 inflect-6.0.4 markupsafe-2.1.1 opentelemetry-api-1.16.0 opentelemetry-exporter-otlp-proto-http-1.16.0 opentelemetry-proto-1.16.0 opentelemetry-sdk-1.16.0 opentelemetry-semantic-conventions-0.37b0 py4j-0.10.9.7 pydantic-1.10.9 soda-core-3.0.39 soda-core-spark-3.0.39 soda-core-spark-df-3.0.39 sqlparse-0.4.4 wrapt-1.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install soda-core-spark-df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6648e77-60ab-445d-9b02-65b1aed77edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from soda.scan import Scan\n",
    "from pyspark.sql.types import LongType, TimestampType, StructType, StringType, DoubleType, IntegerType, StructField\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082fb661-29ed-4000-956c-316e8872485a",
   "metadata": {},
   "source": [
    "## Carregando DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9135aa6d-0176-48fb-b141-cb6fa029cb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49abbaa-47d8-40e3-8aca-f459aeb304a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\",\"false\")\n",
    "\n",
    "yellow_df = spark.read.option('inferSchema',True).parquet('data/raw/yellow/*/*')\n",
    "yellow_df.createOrReplaceTempView(\"yellow_df\")\n",
    "\n",
    "green_df = spark.read.option('inferSchema',True).parquet('data/raw/green/*/*')\n",
    "green_df.createOrReplaceTempView(\"green_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b49b39-abeb-4412-b375-22c95f904ad1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## An√°lise dos DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04c6a7de-fc2b-448c-b0cf-c740a670e72a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yellow_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29d8d970-4ae4-4f0b-9aeb-a92a6510aa13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: long (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: integer (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- trip_type: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "green_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a1a152-25b7-45e2-8013-33373cbea197",
   "metadata": {},
   "source": [
    "## Execu√ß√£o de valida√ß√£o de dados com SODA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e5c2959-595e-4164-9275-92f9d08c8488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checks  =\"\"\"\n",
    "checks for yellow_df:\n",
    "  - row_count > 0\n",
    "  - max(trip_distance) <= 30\n",
    "  - min(trip_distance) > 0\n",
    "  - min(passenger_count) > 0\n",
    "  - max(passenger_count) < 5\n",
    "  - no_datetime_less_than_2018 = 0:\n",
    "      no_datetime_less_than_2018 query: SELECT COUNT(*) FROM yellow_df WHERE tpep_pickup_datetime < '01-01-2018' or tpep_dropoff_datetime < '01-01-2018'\n",
    "  - pickup_lower_than_dropoff = 0:\n",
    "      pickup_lower_than_dropoff query: SELECT COUNT(*) FROM yellow_df WHERE tpep_pickup_datetime > tpep_dropoff_datetime\n",
    "  - duplicate_lines_lower_than = 0:\n",
    "      duplicate_lines_lower_than query: SELECT COUNT(foo.*) FROM (SELECT VendorID ,tpep_pickup_datetime ,tpep_dropoff_datetime ,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag ,PULocationID ,DOLocationID ,payment_type ,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge,airport_fee, COUNT(*) FROM yellow_df GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19 HAVING COUNT(*) > 1) as foo\n",
    "  - schema:\n",
    "      name: Confirm that required columns are present\n",
    "      fail:\n",
    "        when required column missing: [VendorID ,tpep_pickup_datetime ,tpep_dropoff_datetime ,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag ,PULocationID ,DOLocationID ,payment_type ,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge,airport_fee]\n",
    "        when wrong column type:\n",
    "          VendorID: bigint\n",
    "          tpep_pickup_datetime: timestamp_ntz\n",
    "          tpep_dropoff_datetime: timestamp_ntz\n",
    "          passenger_count: double\n",
    "          trip_distance: double\n",
    "          RatecodeID: double\n",
    "          store_and_fwd_flag: string\n",
    "          PULocationID: bigint\n",
    "          DOLocationID: bigint\n",
    "          payment_type: bigint\n",
    "          fare_amount: double\n",
    "          extra: double\n",
    "          mta_tax: double\n",
    "          tip_amount: double\n",
    "          tolls_amount: double\n",
    "          improvement_surcharge: double\n",
    "          total_amount: double\n",
    "          congestion_surcharge: double\n",
    "          airport_fee: double\n",
    "\n",
    "\n",
    "checks for green_df:\n",
    "  - row_count > 0\n",
    "  - min(passenger_count) > 0\n",
    "  - max(passenger_count) < 5\n",
    "  - no_datetime_less_than_2018 = 0:\n",
    "      no_datetime_less_than_2018 query: SELECT COUNT(*) FROM green_df WHERE lpep_pickup_datetime < '01-01-2018' or lpep_dropoff_datetime < '01-01-2018'\n",
    "  - pickup_lower_than_dropoff = 0:\n",
    "      pickup_lower_than_dropoff query: SELECT COUNT(*) FROM green_df WHERE lpep_pickup_datetime > lpep_dropoff_datetime \n",
    "  - duplicate_lines_lower_than = 0:\n",
    "      duplicate_lines_lower_than query: SELECT COUNT(foo.*) FROM (SELECT VendorID, lpep_pickup_datetime, lpep_dropoff_datetime, store_and_fwd_flag, RatecodeID, PULocationID, DOLocationID, passenger_count, trip_distance, fare_amount, extra, mta_tax, tip_amount, tolls_amount, ehail_fee, improvement_surcharge, total_amount, payment_type, trip_type, congestion_surcharge, COUNT(*) FROM green_df GROUP BY 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20 HAVING COUNT(*) > 1) as foo\n",
    "  - schema:\n",
    "      name: Confirm that required columns are present\n",
    "      fail:\n",
    "        when required column missing: [VendorID, lpep_pickup_datetime, lpep_dropoff_datetime, store_and_fwd_flag, RatecodeID, PULocationID, DOLocationID, passenger_count, trip_distance, fare_amount, extra, mta_tax, tip_amount, tolls_amount, ehail_fee, improvement_surcharge, total_amount, payment_type, trip_type, congestion_surcharge]\n",
    "        when wrong column type:\n",
    "            VendorID: bigint\n",
    "            lpep_pickup_datetime: timestamp_ntz\n",
    "            lpep_dropoff_datetime: timestamp_ntz\n",
    "            store_and_fwd_flag: string\n",
    "            RatecodeID: double\n",
    "            PULocationID: bigint\n",
    "            DOLocationID: bigint\n",
    "            passenger_count: double\n",
    "            trip_distance: double\n",
    "            fare_amount: double\n",
    "            extra: double\n",
    "            mta_tax: double\n",
    "            tip_amount: double\n",
    "            tolls_amount: double\n",
    "            ehail_fee: int\n",
    "            improvement_surcharge: double\n",
    "            total_amount: double\n",
    "            payment_type: double\n",
    "            trip_type: double\n",
    "            congestion_surcharge: double\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9837ec37-ea3e-474e-86b5-72b0dd4c3ffe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO   | Soda Core 3.0.39\n",
      "INFO   | Scan summary:\n",
      "INFO   | 5/16 checks PASSED: \n",
      "INFO   |     yellow_df in spark_df\n",
      "INFO   |       row_count > 0 [PASSED]\n",
      "INFO   |       no_datetime_less_than_2018 = 0 [PASSED]\n",
      "INFO   |     green_df in spark_df\n",
      "INFO   |       row_count > 0 [PASSED]\n",
      "INFO   |       no_datetime_less_than_2018 = 0 [PASSED]\n",
      "INFO   |       duplicate_lines_lower_than = 0 [PASSED]\n",
      "INFO   | 11/16 checks FAILED: \n",
      "INFO   |     yellow_df in spark_df\n",
      "INFO   |       pickup_lower_than_dropoff = 0 [FAILED]\n",
      "INFO   |         check_value: 73525.0\n",
      "INFO   |       duplicate_lines_lower_than = 0 [FAILED]\n",
      "INFO   |         check_value: 1.0\n",
      "INFO   |       Confirm that required columns are present [FAILED]\n",
      "INFO   |         fail_column_type_mismatch[passenger_count] expected(double) actual(bigint)\n",
      "INFO   |         fail_column_type_mismatch[RatecodeID] expected(double) actual(bigint)\n",
      "INFO   |         schema_measured = [VendorID bigint, tpep_pickup_datetime timestamp_ntz, tpep_dropoff_datetime timestamp_ntz, passenger_count bigint, trip_distance double, RatecodeID bigint, store_and_fwd_flag string, PULocationID bigint, DOLocationID bigint, payment_type bigint, fare_amount double, extra double, mta_tax double, tip_amount double, tolls_amount double, improvement_surcharge double, total_amount double, congestion_surcharge double, airport_fee double]\n",
      "INFO   |       max(trip_distance) <= 30 [FAILED]\n",
      "INFO   |         check_value: 389678.46\n",
      "INFO   |       min(trip_distance) > 0 [FAILED]\n",
      "INFO   |         check_value: -37264.53\n",
      "INFO   |       min(passenger_count) > 0 [FAILED]\n",
      "INFO   |         check_value: 0\n",
      "INFO   |       max(passenger_count) < 5 [FAILED]\n",
      "INFO   |         check_value: 192\n",
      "INFO   |     green_df in spark_df\n",
      "INFO   |       pickup_lower_than_dropoff = 0 [FAILED]\n",
      "INFO   |         check_value: 427.0\n",
      "INFO   |       Confirm that required columns are present [FAILED]\n",
      "INFO   |         fail_column_type_mismatch[RatecodeID] expected(double) actual(bigint)\n",
      "INFO   |         fail_column_type_mismatch[passenger_count] expected(double) actual(bigint)\n",
      "INFO   |         fail_column_type_mismatch[payment_type] expected(double) actual(bigint)\n",
      "INFO   |         schema_measured = [VendorID bigint, lpep_pickup_datetime timestamp_ntz, lpep_dropoff_datetime timestamp_ntz, store_and_fwd_flag string, RatecodeID bigint, PULocationID bigint, DOLocationID bigint, passenger_count bigint, trip_distance double, fare_amount double, extra double, mta_tax double, tip_amount double, tolls_amount double, ehail_fee int, improvement_surcharge double, total_amount double, payment_type bigint, trip_type double, congestion_surcharge double]\n",
      "INFO   |       min(passenger_count) > 0 [FAILED]\n",
      "INFO   |         check_value: 0\n",
      "INFO   |       max(passenger_count) < 5 [FAILED]\n",
      "INFO   |         check_value: 48\n",
      "INFO   | Oops! 11 failures. 0 warnings. 0 errors. 5 pass.\n"
     ]
    }
   ],
   "source": [
    "scan = Scan()\n",
    "\n",
    "scan.set_scan_definition_name(\"Datasets validation\")\n",
    "scan.set_data_source_name(\"spark_df\")\n",
    "scan.add_spark_session(spark)\n",
    "\n",
    "scan.add_sodacl_yaml_str(checks)\n",
    "\n",
    "scan.execute()\n",
    "print(scan.get_logs_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b406e1a-c97f-46a4-bc91-fb62ff8dcf20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55da86-9bde-4368-8b2a-78b2b90c6e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a403b-b546-42bd-8439-bb694d6b24b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}